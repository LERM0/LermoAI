FROM ghcr.io/ggerganov/llama.cpp:server--b1-9635529

RUN apt-get install curl

RUN mkdir -p /models && \
    chmod -R 777 /models

RUN curl -L https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf --output /models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

ENTRYPOINT /server --model /models/mistral-7b-instruct-v0.2.Q4_K_M.gguf \
    -c 512 \
    --host 0.0.0.0 \
    --port 8080 \
    --ctx-size 2048 \
    --parallel 1 \
    --n-predict 2048
